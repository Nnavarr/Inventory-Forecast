---
title: "Inventory Forecast"
author: "Noe Navarro"
date: "February 11, 2019"
output: html_document
---


```{r Library}

library('dplyr')
library('forecast', lib.loc="~/R/win-library/3.4")
library('ggvis')
library('ggplot2')
library('xts')
library('broom')
library('stats')
library('lmtest')
library('DT')

```



#** Initial Data **

```{r}

# Import Data ----
hitch_units <- read.csv("\\\\adfs01.uhi.amerco\\departments\\mia\\group\\MIA\\Noe\\Projects\\Hitch Inventory\\Data\\hitch_units.csv")

# Rename columns ----
colnames(hitch_units)[1] <- 'Part_Number'

# Convert "Date" column to Date values ----
hitch_units$Date <- as.character(hitch_units$Date)
hitch_units$Date <- as.Date(hitch_units$Date, format = '%m/%d/%Y')

# Convert Part_Number column to character (not factor) ----
hitch_units$Part_Number <- as.character(hitch_units$Part_Number)

# Order by part number ASC ----
hitch_units <-
  hitch_units %>%
  arrange(`Part_Number`)

```



# Prior to this step, the shiny app will need to import a csv file contianing inventory unit counts. There may be room to import a single file at once where the user can filter based on part number. 


```{r Import Regression Format Data}

# Create regression model dataframe with categorical monthly variables ----
format_data <- function(x){
  
  require('dplyr')
  require('lazyeval')
  require('purrr')
  
  # Create trend and month columns ----
  x$Trend = ""
  x$Feb = ""
  x$Mar = ""
  x$Apr = ""
  x$May = ""
  x$Jun = ""
  x$Jul = ""
  x$Aug = ""
  x$Sep = ""
  x$Oct = ""
  x$Nov = ""
  x$Dec = ""
  
  # Create Trend column sequence ----
  x <- 
    x %>%
    group_by(Part_Number) %>%
    mutate(Trend = seq_along(Part_Number))
  
  
  for(i in seq_along(x$Date)){
    
    if(months(x$Date)[i] == 'February'){
      
      x$Feb[i] = 1
      
    } else if(months(x$Date)[i] == 'March'){
      
      x$Mar[i] = 1
      
    } else if(months(x$Date)[i] == 'April'){
      
      x$Apr[i] = 1
      
    } else if(months(x$Date)[i] == 'May'){
      
      x$May[i] = 1
      
    } else if(months(x$Date)[i] == 'June'){
      
      x$Jun[i] = 1
      
    } else if(months(x$Date)[i] == 'July'){
      
      x$Jul[i] = 1
      
    } else if(months(x$Date)[i] == 'August'){
      
      x$Aug[i] = 1
      
    } else if(months(x$Date)[i] == 'September'){
      
      x$Sep[i] = 1
      
    } else if(months(x$Date)[i] == 'October'){
      
      x$Oct[i] = 1
      
    } else if(months(x$Date)[i] == 'November'){
      
      x$Nov[i] = 1
      
    } else if(months(x$Date)[i] == 'December'){
      
      x$Dec[i] = 1
      
    } 
  }
  
  # Replace blank value with 0 ----
  x$Feb[x$Feb == ""] <- 0
  x$Mar[x$Mar == ""] <- 0
  x$Apr[x$Apr == ""] <- 0
  x$May[x$May == ""] <- 0
  x$Jun[x$Jun == ""] <- 0
  x$Jul[x$Jul == ""] <- 0
  x$Aug[x$Aug == ""] <- 0
  x$Sep[x$Sep == ""] <- 0
  x$Oct[x$Oct == ""] <- 0
  x$Nov[x$Nov == ""] <- 0
  x$Dec[x$Dec == ""] <- 0
  
  # Convert columns to numeric ----
  x$Feb <- as.numeric(x$Feb)
  x$Mar <- as.numeric(x$Mar)
  x$Apr <- as.numeric(x$Apr)
  x$May <- as.numeric(x$May)
  x$Jun <- as.numeric(x$Jun)
  x$Jul <- as.numeric(x$Jul)
  x$Aug <- as.numeric(x$Aug)
  x$Sep <- as.numeric(x$Sep)
  x$Oct <- as.numeric(x$Oct)
  x$Nov <- as.numeric(x$Nov)
  x$Dec <- as.numeric(x$Dec)
                      
   return(x)
  
}
  

```


# Part Number Selection (via Shiny App) ----

Here, the dataframe created from the function above will be filtered based on user input. We can then proceed to build the regression model and return any metrics we may need. 

Within the following R-Script, we will assume a selection has already been made. Here, we will manually set the selection to part number: 13002

```{r Manual Selection of Part number 74507}

p_13002_test <- 
test_function %>%
  filter(`Part_Number` == '74507')

```


```{r Pre Model Specifications}

observations <-
  round(max(p_13002_test$Trend),0)

years_data <- round(observations/12,2)

pre_model_summary <- data.table(as.tbl(data.frame(observations, years_data)))
colnames(pre_model_summary)[1] <- 'Count'
rownames(pre_model_summary) <- c('Observations', 'Yrs Data')

print(pre_model_summary)

```


At this point, the user has an understanding of how much data is available. We can then prompt the user to determine the test / training split. 

** SHINY ** : Ask the user to exclude X observations (12 months by default)


```{r Manual exclusion of 12 obs}

p_13002_test

head(p_13002_test)

# Test Subset ----
training_df <- subset(p_13002_test, Trend <= max(Trend) - 12) # Here, the 12 would be the user entered excluded observations ----

```

After the subset, the model can be run on the newly created 'training_df' 

```{r LM Creation}

# Training Model Creation ----
training_model <- lm(Units ~
                       Trend 
                     + Feb
                     + Mar
                     + Apr 
                     + May
                     + Jun
                     + Jul
                     + Aug
                     + Sep 
                     + Oct
                     + Nov 
                     + Dec,
                     data = training_df)

# Training Model Summary ----
t_model_summary <- summary(training_model)

# Establish Crititcal T and F values based on model Degrees of Freedom ----

# Critial T = Two Trailed, N-K-1 Degrees of Freedom & Critical F = one tailed test ----
n_k_1 <- training_model$df.residual
k = 12

critical_t <- round(abs(qt(.05/2, n_k_1)),3)
critical_f <- qf(.95,  df1 = k, df2 = n_k_1)

```


```{r Regression Function}

regression_metrics_training <- function(x){
  
  # The x variable represents the subset of part number DF. This will test our regression model prior to implementation. If out-of-sample accuracy is deemed acceptable, we can proceed with a full data set model.
  
  require('dplyr')
  require('lazyeval')
  require('purrr')
  
  # Create the LM (OLS regression) ----
  model = lm(Units ~
               Trend 
             + Feb
             + Mar
             + Apr 
             + May
             + Jun
             + Jul
             + Aug
             + Sep 
             + Oct
             + Nov 
             + Dec,
             data = x)
  
  t_model_summary <- summary(training_model)

  
  # Establish Crititcal T and F values based on model Degrees of Freedom ----
  # Critial T = Two Trailed, N-K-1 Degrees of Freedom & Critical F = one tailed test ----
  n_k_1 <- training_model$df.residual
  k = t_model_summary$fstatistic[2]

  critical_t <- round(abs(stats::qt(.05/2, n_k_1)),3)
  critical_f <- stats::qf(.95,  df1 = k, df2 = n_k_1)
  critical_chi <- stats::qchisq(.95, df = k)

  # -----------------------------------------------
  # Model Calibration Test 1: Multicolinearity ----
  # -----------------------------------------------
  
  # Independent X variable significance ----
  coefficient_pval <- t_model_summary$coefficients[,4]
  significance_x_var <- coefficient_pval < .05
  significance_x_var_boolean <- sum(significance_x_var) > 0
    
    # In the code above, if one X (independent) variable is significant, it will return TRUE.
  
  # F-test (all X variables combined; H0: All beta coefficients = 0 ; Ha: At least one beta coefficient != 0)
  significant_f_boolean <- t_model_summary$fstatistic[1] > critical_f
  
  # Multicolinearity conclusion ----
  multicolinearity_conflict <- significance_x_var_boolean != significant_f_boolean
  
  multicolinearity_results <-
    
    if(multicolinearity_conflict == FALSE){
    
      print("Not Detected")
    
    } else {
    
      print("Detected")
    
    }
  
  # -------------------------------------------------
  # Model Calibration Test 2: Heteroskedasticity ----
  # -------------------------------------------------
  
  augmented_model <- broom::augment(model)
  
  # Breusch-Pagan Test: Regress X variables on squared residuals from first regression ----
  resid_model = lm(.resid^2 ~
                     Trend 
                   + Feb
                   + Mar
                   + Apr 
                   + May
                   + Jun
                   + Jul
                   + Aug
                   + Sep 
                   + Oct
                   + Nov 
                   + Dec,
                   data = augmented_model)
  
  # Residual model summary ----
  resid_model_summary <- summary(resid_model)
  
  # Breusch-Pagan value: R-squared from residual regression * N (one tailed; only an issue if too big) ----
  bp_val <- resid_model_summary$r.squared * max(augment_model$Trend) 

  heteroskedasticity_results <- 
    
    if(bp_val > critical_chi){
  
      print("Detected")
  
    } else {
  
      print("Not Detected")
  
    }

  # ----------------------------------------------
  # Model Calibration Test 3: Autocorrelation ----
  # ----------------------------------------------
  
  durbin_value <- lmtest::dwtest(reg_model)
  durbin_watson_pvalue <- durbin_value$p.value
  autocorrelation_results <-
  
    if(durbin_watson_pvalue < .05){
    
      print("Detected")
    
    } else {
    
      print("Not Detected")
    
    }
  
  
  # Model Summary ----

  
  
  
  
}



# TODO: Find a way to extract the number of observations for each part numner **UPON SELECTION** of a dropdown list 
# Once this process is created, we can prompt the user for input on training vs test set splits (typically 80/20)
# After, we can compile error metrics for out-of-sample data. 

```


```{r Test initial function Working 2-26-2019}

test_function <- 
  format_data(hitch_units)

```

```{r Graph Unit Count Time Series}

# Graph time series ----
test_function %>% 
  ggvis(x = ~Date, y = ~Units)

```

```{r Build Regression Model}

# initial model ----
reg_model <-
  lm(Units ~ Trend + Feb + Mar + Apr + May + Jun + Jul + Aug + Sep + Oct + Nov + Dec, data = test_function)

# Model Summary ----
model_summary <-
  summary(reg_model)

augment_model <-
  augment(reg_model)

glance_model <- 
  glance(reg_model)


```

```{r Critical T Value @ 95% condifence}

# Critical T Values (used for confidence intervals and Coefficient test; two tailed) ----
round(abs(qt(.05/2, 10)),3)

# Critical F value (one tailed Test) ----
# k = 12 (x variables)
# n-k-1 = 33
qf(.95,  df1 = 12, df2 = glance_model$df.residual)


```

```{r Multicolinearity Test}

# In this section, we will check the F-Test and whether it shows significance vs all independent variables. Here, we would like to check whether there is a conflict between the F test and individual coefficient significance. The F-test tells us at least one independent variable explains a large portion of Y's variation. If no x variables are significant while F is, multicolinearity is present. 

# Extract Individual X variable P values ----
coefficient_pval <- model_summary$coefficients[,4]
significance_x_var <- coefficient_pval < .05
significance_x_var_boolean <- sum(significance_x_var) > 0

# Manual check of computed T statitic / P value ----
model_summary$coefficients
st_error <- model_summary$coefficients[, 2]
coeffi <- model_summary$coefficients[, 1]
t_stat <- coeffi / st_error # The manual calculation of T values is the same as regression summary output ----

model_summary$fstatistic
f_crit <- qf(.95, df1 = model_summary$fstatistic[2], model_summary$fstatistic[3])

# ANOVA Table Check (Manual) ----
anova_table <- anova(reg_model)
msr <- (sum(anova_table$`Mean Sq`[1:12]) / model_summary$fstatistic[2])
mse <- anova_table$`Mean Sq`[13]
f_stat_manual <- msr / mse
# The manual anova check reveals the F statistic from the model_summary is correct; We can move ahead with this value. 
significant_f_boolean <- model_summary$fstatistic[1] > f_crit


# Multicolinearity check ----
multicolinearity_conflict <- significance_x_var_boolean != significant_f


# Multicolinearity Results ----
multicolinearity_results <-
  if(multicolinearity_conflict == FALSE){
    
    print("Not Detected")
    
  } else {
    
    print("Detected")
    
  }

```

```{r Heteroskedasticity Test}

# Breush Pagan Test ----
bptest(reg_model, studentize = TRUE) # Null hypothesis = no heteroskedascticity present. 


# Manual BP Test ----
resid_lm <- 
  lm((.resid^2) ~ Trend + Feb + Mar + Apr + May + Jun + Jul + Aug + Sep + Oct + Nov + Dec, data = augment_model)

resid_model_summary <- summary(resid_lm)

augment_model %>%
  ggvis(x = ~.fitted, y = ~.resid)

# Manual BP Calc ----
bp_val <- resid_model_summary$r.squared * 12

# Critical Chi Square 95% confidence @ 12 DF ----
chi_critical = 21.026

qchisq(.95, df = 12)


# Check against calculated BP value ----
bp_val > chi_critical

heteroskedasticity_results <- 
  if(bp_val > chi_critical){
  
    print("Detected")
  
  } else {
  
    print("Not Detected")
  
  }

print(heteroskedasticity_results)

```

```{r Autocorrelation: Durbin-Watson Test}

durbin_value <- lmtest::dwtest(reg_model)

durbin_watson_pvalue <- durbin_value$p.value

autocorrelation_results <-
  if(durbin_watson_pvalue < .05){
    
    print("Detected")
    
  } else {
    
    print("Not Detected")
    
  }


```

```{r Model Summary Table}

# Multicolinearity
# Heteroskedasticity
# Autocorrelation 

Test <- c('Multicolinearity', 'Heteroskedasticity', 'Autocorrelation')
Result <- c(multicolinearity_results, heteroskedasticity_results, autocorrelation_results)

# Table compilation ----
model_calibration_results <- data.table(as.tbl(data.frame(Test, Result)))
DT::datatable(model_calibration_results)


print(model_calibration_results)


```


```{r Forecast Summary Table}






```






```{r Graph Output}





```






